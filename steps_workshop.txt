- make repo: housePrice folder, add __init__.py file   | create folder tests
initial idea: evaluate model in CV

######### MAKE A FUNCTIONAL FAILING TEST
# FIrst, we start by defining what we want to achieve.
# I see Kaggle like 2 dependant pieces of work:
    > build a good model, ergo, we need to evaluate a model on cv
    > Submit predictions to kaggle

- create test file: tests/test_eval_model.py
- create test: def test_eval_model()

df = DDF({
    'MSZoning': ['FV', 'RH', 'RM'],
    'MiscFeature': [np.nan, 'Gar2', 'Othr'],
    'MoSold': [2, 5, 9],
    'SalePrice': [1000, 20000, 400000]
    })

def test_eval_model_on_cv(tmpdir):
    df = load_df(TRAIN_PATH, nrows=10)
    model_params = {'min_data': 1, 'min_data_in_bin': 1}
    log_path = str(tmpdir) + 'file.csv'
    ev.eval_model_on_cv(
            df=df, log_file=log_path,
            extra_model_params=model_params)
    results_df = DDF.from_csv(log_path)
    assert len(results_df) == 1
    assert results_df['rmse'][0] > 0

- run tests and it will fail
- cannot import data, fix it, create load_df and TRAIN_PATH

TRAIN_PATH = os.path.join(utils.paths.dropbox(), 'HousePricesData/train.csv')
def load_df(data_path, nrows=None):
    return DDF.from_csv(data_path, nrows=nrows)

######### MAKE THE TEST PASS

To make this test pass, we need this function to be created, and return what we expect
- create file: eval_model.py
- create function: eval_model_on_cv
   s: abstraction levels, general steps

def eval_model_on_cv(df, log_file, extra_model_params={}):
    df = clean_data(df)
    df = add_features(df)
    mm, targets = get_mm(df), get_targets(df)
    ixs = get_cv_ixs(df)
    model = get_model(**extra_model_params)
    fitter = CVFitter(model)
    results = fitter.fit(mm, targets, ixs, early_stopping_rounds=50)
    preds = results['combined_preds']
    evals = evaluate_preds(preds, targets)
    wutils.io.append_csv(evals, log_file)
    return evals


Then we have our pipeline built, roughly at one high level of abstraction, and now we need to
start building the individual functions. We can build some of these functions together. The idea
is to make work the entire pipeline with few elements. Afterwards, we can try to improve


####### Write a failing test (unit test)  clean_data
def test_clean_data():
    result_df = ev.clean_data(df)
    assert result_df['MSZoning'].dtype == float
    assert np.all(df['MoSold'] == result_df['MoSold'])


####### Make the test pass               clean_data
def clean_data(df):
    str_columns = wutils.np.get_str_columns(df)
    for col in str_columns:
        df[col] = wutils.features.categorical_to_numeric(df, col)
    for col in set(df.columns) - set([target_name]):
        df[col] = wutils.np.fillna(df[col], -99)
    return df


####### Write a failing test (unit test)  add_features
def test_add_features():
    result_df = ev.add_features(df)
    assert 'f:MoSold**2' in result_df


####### Make the test pass
def add_features(df):
    df['f:MoSold**2'] = df['MoSold'] ** 2
    return df


####### Write a failing test (unit test)  get_mm and get_targets
def test_get_mm():
    result_df = ev.get_mm(df)
    assert 'SalesPrice' not in result_df.columns


def get_mm(df):
    columns_to_drop = [target_name, 'Id', 'LotAreaCut']
    mm_cols = [col for col in df.columns if col not in columns_to_drop]
    return df.colslice(mm_cols)


####### Make the test pass
add target_name
def get_mm(df):
    columns_to_drop = [target_name]
    mm_cols = [col for col in df.columns if col not in columns_to_drop]
    return df.colslice(mm_cols)


def get_targets(df):
    return np.log(df[target_name])


####### Write a failing test (unit test)  add_features
def test_get_cv_ixs():
    ixs = ev.get_cv_ixs(df)
    expected_ixs = {
            0: {'train': np.array([True, True, False]),
                'val': np.array([False, False, True])},
            1: {'train': np.array([False, False, True]),
                'val': np.array([True, True, False])}
            }
    for fold in expected_ixs:
        assert np.all(ixs[fold]['train'] == expected_ixs[fold]['train'])
        assert np.all(ixs[fold]['val'] == expected_ixs[fold]['val'])


####### Make the test pass
def get_cv_ixs(df, split_ratio=0.5):
    order = np.arange(len(df))
    split_point = round(len(df) * split_ratio, 0) - 1
    train_ixs = order <= split_point
    result = OrderedDict({
        0: {'train': train_ixs, 'val': ~train_ixs},
        1: {'train': ~train_ixs, 'val': train_ixs}
        })
    return result


####### Function too simple to have a test?
get_model: This function is very simple. Sometimes I wouldn't write a test for such
a simple function, but still something can go wrong (forget to put the update, etc)

def get_model(**kwargs):
    params = {
            'n_estimators': 9999,
            'max_depth': 20
            }
    params.update(kwargs)
    model = wutils.models.LGBRModel(params)
    return model


####### Write a failing test (unit test)  evaluate_preds
def test_evaluate_preds():
    preds = np.log(np.array([1000, 20000, 400000]))
    targets = preds[:]
    result = ev.evaluate_preds(preds, targets)
    for metric in result:
        assert result[metric] == 0


def evaluate_preds(preds, targets):
    evals = {
            'rmse': mean_squared_error(targets, preds) ** (1./2),
            'mae': mean_absolute_error(targets, preds)
            }
    return evals
